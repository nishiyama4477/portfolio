{
 "metadata": {
  "language_info": {
   "name": "python",
   "version": "3.7.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "##Import packages\n",
    "\n",
    "import Python packages you need in this session. Also display the Azure Machine Learning SDK version."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##Connect to a workspace\n",
    "\n",
    "Create a workspace object from the existing workspace.<br>\n",
    "```Workspace.from_config()```reads the file config.json and loads the details into an object named ws."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.location, ws.resource_group, sep='\\t')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##Create an experiment\n",
    "\n",
    "Create an experiment to track the runs in your workspace. A workspace can have multiple experiments."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from azureml.core import Experiment\n",
    "experiment_name = 'Potato-chips-classification'\n",
    "\n",
    "exp = Experiment(workspace=ws, name=experiment_name)"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##Create or attach and existing compute target\n",
    "\n",
    "The code below creates the compute clusters for you if they don't already exist in your workspace. If the AmlComputer with that name is already in your workspace the code will skip the creation process.<br>\n",
    "This time we'll use the size of Standard NC6s V3 for GPU operation. You will submit Python code to run on this VM later."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "import os\n",
    "\n",
    "compute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", \"cpu-cluster-6s\")\n",
    "compute_min_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MIN_NODES\", 0)\n",
    "compute_max_nodes = os.environ.get  (\"AML_COMPUTE_CLUSTER_MAX_NODES\", 4)\n",
    "\n",
    "vm_size = os.environ.get(\"AML_COMPUTE_CLUSTER_SKU\", \"STANDARD_NC6S_V3\")\n",
    "\n",
    "if compute_name in ws.compute_targets:\n",
    "    compute_target = ws.compute_targets[compute_name]\n",
    "    if compute_target and type(compute_target) is AmlCompute:\n",
    "        print('found compute target. just use it. ' + compute_name)\n",
    "else:\n",
    "    print('creating a new compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size=vm_size,\n",
    "    min_nodes=compute_min_nodes,\n",
    "    max_nodes=compute_max_nodes)\n",
    "\n",
    "    compute_target = ComputeTarget.create(\n",
    "        ws, compute_name, provisioning_config)\n",
    "\n",
    "    compute_target.wait_for_completion(\n",
    "        show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "\n",
    "    print(compute_target.get_status().serialize())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##Download the dataset\n",
    "\n",
    "Download the dataset registered in your workspace.<br>\n",
    "\n",
    "3 step how to create a dataset<br>\n",
    "<br>\n",
    "1: Upload the data folder in a blob Container\n",
    "<br>\n",
    "2: Create the Datastore from the blob Container\n",
    "<br>\n",
    "3: Create the Dataset from the Datastore"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from azureml.core import Workspace, Dataset\n",
    "\n",
    "data_folder = os.path.join(os.getcwd(), 'data')\n",
    "os.makedirs(data_folder, exist_ok=True)\n",
    "\n",
    "subscription_id = '0c3a9701-fb22-41b3-b904-89b9960d70d6'\n",
    "resource_group = 'Koichi_1'\n",
    "workspace_name = 'koichi 1'\n",
    "\n",
    "workspace = Workspace(subscription_id, resource_group, workspace_name)\n",
    "\n",
    "dataset = Dataset.get_by_name(workspace, name='potatochips-data-dataset')\n",
    "dataset.download(data_folder, overwrite=True)"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##Create a directory for script\n",
    "\n",
    "Create a directory to deliver the necessary code from your computer to the remote resource."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "script_folder = os.path.join(os.getcwd(), 'potatochips_script')\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##Create a training script\n",
    "\n",
    "To submit the job to the cluster, first create a training script. Run the following code to create the training script called ```train.py``` in the directory you just created."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "%%writefile $script_folder/train.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from azureml.core import Run\n",
    "\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--data-folder', type=str, dest='data_folder', help='data folder mounting point')\n",
    "parser.add_argument('--optimizer', type=str, dest='arg_optimizer', help='optimizer')\n",
    "parser.add_argument('--monitor', type=str, dest='arg_monitor', help='Learning_rate_reduction_monitor')\n",
    "parser.add_argument('--batchsize', type=int, dest='arg_batchsize', help='batchsize')\n",
    "parser.add_argument('--epochs', type=int, dest='arg_epochs', help='epochs')\n",
    "parser.add_argument('--Learning_rate', type=float, dest='arg_Learning_rate', help='Learning_rate')\n",
    "args = parser.parse_args()\n",
    "\n",
    "arg_optimizer = args.arg_optimizer\n",
    "arg_monitor = args.arg_monitor\n",
    "arg_batchsize = args.arg_batchsize\n",
    "arg_epochs = args.arg_epochs\n",
    "arg_Learning_rate = args.arg_Learning_rate\n",
    "\n",
    "data_folder = args.data_folder\n",
    "print('Data folder:', data_folder)\n",
    "\n",
    "training_folder = os.path.join(data_folder, \"potato-chips\")\n",
    "print('Training folder:', training_folder)\n",
    "\n",
    "if arg_optimizer == \"SGD\":\n",
    "  optimizer = optimizers.SGD(lr=arg_Learning_rate)\n",
    "elif arg_optimizer == \"RMSprop\":\n",
    "  optimizer = optimizers.RMSprop(lr=arg_Learning_rate)\n",
    "elif arg_optimizer == \"Adam\":\n",
    "  optimizer = optimizers.Adam(lr=arg_Learning_rate)\n",
    "else:\n",
    "  optimizer = 'rmsprop'\n",
    "\n",
    "FAST_RUN = False\n",
    "IMAGE_WIDTH = 192\n",
    "IMAGE_HEIGHT = 256\n",
    "IMAGE_SIZE = (IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "IMAGE_CHANNELS = 3\n",
    "\n",
    "filenames = os.listdir(training_folder)\n",
    "categories = []\n",
    "for filename in filenames:\n",
    "  category = filename.split('.')[0]\n",
    "  categories.append(category)\n",
    "  \n",
    "df = pd.DataFrame({\n",
    "  'filename' : filenames,\n",
    "  'category' : categories\n",
    "})\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "earlystop = EarlyStopping(patience=10)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor=arg_monitor,\n",
    "                                            patience=2,\n",
    "                                            verbose=1,\n",
    "                                            factor=0.5,\n",
    "                                            min_lr=0.00001)\n",
    "\n",
    "# callbacks = [earlystop, learning_rate_reduction]\n",
    "callbacks = [learning_rate_reduction]\n",
    "\n",
    "train_df, validate_df = train_test_split(df, test_size=0.20, random_state=42)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "validate_df = validate_df.reset_index(drop=True)\n",
    "\n",
    "total_train = train_df.shape[0]\n",
    "total_validate = validate_df.shape[0]\n",
    "batch_size=arg_batchsize\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    training_folder,\n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size,\n",
    "    validate_filenames=False\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "    validate_df,\n",
    "    training_folder,\n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size,\n",
    "    validate_filenames=False\n",
    ")\n",
    "\n",
    "run = Run.get_context()\n",
    "\n",
    "epochs = 3 if FAST_RUN else arg_epochs\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=total_validate//batch_size,\n",
    "    steps_per_epoch=total_train//batch_size,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "\n",
    "run.log('optimizer', arg_optimizer)\n",
    "run.log('monitor', arg_monitor)\n",
    "run.log('batchsize', arg_batchsize)\n",
    "run.log('epochs', arg_epochs)\n",
    "run.log('accuracy', history.history['accuracy'][-1])\n",
    "run.log('val_accuracy', history.history['val_accuracy'][-1])\n",
    "run.log('loss', history.history['loss'][-1])\n",
    "run.log('val_loss', history.history['val_loss'][-1])\n",
    "\n",
    "val_accuracy = history.history['val_accuracy'][-1]\n",
    "\n",
    "from azureml.core.run import Run\n",
    "run_logger = Run.get_context()\n",
    "run_logger.log(\"accuracy\", float(val_accuracy))\n",
    "\n",
    "output_folder = os.path.join(os.getcwd(), \"outputs\")\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "model.save_weights(os.path.join(os.getcwd(),\"model.h5\"))"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##Create an envirionment that contains the libraries needed to run the script\n",
    "\n",
    "create the Environment that contains: tensorflow library, matplotlib library, the scikit-learn library, and azureml-defaults which contains the dependencies for logging metrics, and dependencies required for deploying the model as a web service.<br>\n",
    "<br>\n",
    "Once the environment is defined, register it with the Workspace."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from azureml.core.environment import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "env = Environment('potato-env')\n",
    "cd = CondaDependencies.create(pip_packages=['azureml-defaults', 'tensorflow', 'matplotlib'],conda_packages=['scikit-learn==0.22.1'])\n",
    "\n",
    "env.python.conda_dependencies = cd\n",
    "env.register(workspace=ws)"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##Sampling the hyperparameter space\n",
    "<br>\n",
    "This time, I use Random sampling.\n",
    "In random sampling, hyperparameter values are randomly selected from the defined search space.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from azureml.train.hyperdrive import RandomParameterSampling\n",
    "from azureml.train.hyperdrive import choice, loguniform\n",
    "\n",
    "param_sampling = RandomParameterSampling( {\n",
    "    \"--optimizer\": choice('SGD', 'RMSprop', 'Adam'),\n",
    "    \"--monitor\": choice('val_accuracy', 'val_loss'),\n",
    "    \"--batchsize\": choice(16, 32, 64),\n",
    "    \"--epochs\": choice(30, 50, 70, 90, 120, 150),\n",
    "    \"--Learning_rate\": loguniform(-4, -1)\n",
    "})"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##Specify primary metric\n",
    "\n",
    "Specify the primary metric you want hyperparameter tuning to optimize. Each traning run is evaluated for the primary metric. The early termination policy uses the primary metric to identify low-perfrmance runs.\n",
    "<br>\n",
    "This time, I specify \"accuracy\" as the primary metric goal to maximize."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from azureml.train.hyperdrive import PrimaryMetricGoal\n",
    "primary_metric_name=\"accuracy\",\n",
    "primary_metric_goal=PrimaryMetricGoal.MAXIMIZE"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##Bandit policy\n",
    "\n",
    "Bandit ends runs when the primary metric isn't within the spefified slack factor/slack amount of the most successful run.\n",
    "<br>\n",
    "This time, I use slack factor. If a primary metric reported at interval of best performing run is 0.9 with a goal to maximize the primary metric,any training runs whose best metric at interval is less than 0.81...(0.9/(1 + 0.1)) will be terminated."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from azureml.train.hyperdrive import BanditPolicy\n",
    "early_termination_policy = BanditPolicy(slack_factor = 0.1, evaluation_interval=1, delay_evaluation=5)"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##Configure the traninig job\n",
    "\n",
    "Create the ScriptRunConfig by specifying the training script, compute target and environment."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from azureml.core import ScriptRunConfig\n",
    "\n",
    "args = ['--data-folder', dataset.as_mount()]\n",
    "\n",
    "src = ScriptRunConfig(source_directory=script_folder,\n",
    "                                        script='train.py',\n",
    "                                        arguments=args,\n",
    "                                        compute_target=compute_target,\n",
    "                                        environment=env)"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##Configure hyperparameter tuning experiment"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from azureml.train.hyperdrive import HyperDriveConfig\n",
    "hd_config = HyperDriveConfig(run_config=src,\n",
    "                            hyperparameter_sampling=param_sampling,\n",
    "                            policy=early_termination_policy,\n",
    "                            primary_metric_name='accuracy',\n",
    "                            primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
    "                            max_total_runs=100,\n",
    "                            max_concurrent_runs=4)"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##Submit hyperparameter tuning experiment"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from azureml.core.experiment import Experiment\n",
    "experiment = Experiment(workspace, experiment_name)\n",
    "hyperdrive_run = experiment.submit(hd_config)"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##Jupyter widget"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from azureml.widgets import RunDetails\nRunDetails(hyperdrive_run).show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}