{"metadata":{"language_info":{"name":"python","version":"3.7.8","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Import packages","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nfrom keras.preprocessing.image import ImageDataGenerator, load_img\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport random\nimport os","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create constant values","metadata":{}},{"cell_type":"code","source":"FAST_RUN = False\nIMAGE_WIDTH=192\nIMAGE_HEIGHT=256\nIMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\nIMAGE_CHANNELS=3","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Add labels to each category","metadata":{}},{"cell_type":"code","source":"filenames = os.listdir(\"./train_data\")\ncategories = []\nfor filename in filenames:\n    category = filename.split('.')[0]\n    categories.append(category)\n\ndf = pd.DataFrame({\n    'filename': filenames,\n    'category': categories\n})","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"see df","metadata":{}},{"cell_type":"code","source":"df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"See total in count","metadata":{}},{"cell_type":"code","source":"df['category'].value_counts().plot.bar()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Build model with Xception","metadata":{}},{"cell_type":"code","source":"from keras.models import Sequential, Model\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n\n# Xception用\nfrom keras.applications.xception import Xception\nfrom keras.layers.pooling import GlobalAveragePooling2D\n\nxception=Xception(input_shape = (IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS),include_top=False,weights='imagenet')\n\nx = xception.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(1024, activation = 'relu')(x)\npredictions = Dense(7, activation = 'softmax')(x)\n\nmodel = Model(inputs = xception.input, outputs = predictions)\n\n# Freeze the layers of Xception model expect batch normalization\nfor layer in model.layers:\n    layer.trainable = False\n\n    if layer.name.startswith('batch_normalization'):\n        layer.trainable = True\n    if layer.name.endswith('bn'):\n        layer.trainable = True\n        \nmodel.compile(\n    optimizer = 'adam',\n    loss = 'categorical_crossentropy',\n    metrics = [\"accuracy\"]\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"See the model","metadata":{}},{"cell_type":"code","source":"model.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create callbacks","metadata":{}},{"cell_type":"code","source":"from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\nearlystop = EarlyStopping(monitor = 'val_loss', \n                          patience = 10,\n                          verbose = 1)\n\nlearning_rate_reduction = ReduceLROnPlateau(monitor = 'val_loss',\n                                            factor = 0.1,\n                                            patience = 3,\n                                            verbose = 1,\n                                            min_lr=0.00001)\n\ncallbacks = [earlystop, learning_rate_reduction]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Split df into train and validate data","metadata":{}},{"cell_type":"code","source":"train_df, validate_df = train_test_split(df, test_size=0.20, random_state=42)\ntrain_df = train_df.reset_index(drop=True)\nvalidate_df = validate_df.reset_index(drop=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"See the amount of train_df and validate_df","metadata":{}},{"cell_type":"code","source":"train_df['category'].value_counts().plot.bar()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validate_df['category'].value_counts().plot.bar()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_train = train_df.shape[0]\ntotal_validate = validate_df.shape[0]\nbatch_size=32 ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Data Augmentation","metadata":{}},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    rotation_range=15,\n    rescale=1./255,\n    shear_range=0.1,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    width_shift_range=0.1,\n    height_shift_range=0.1\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create Train and Validate Data","metadata":{}},{"cell_type":"code","source":"train_generator = train_datagen.flow_from_dataframe(\n    train_df, \n    \"./train_data/\", \n    x_col='filename',\n    y_col='category',\n    target_size=IMAGE_SIZE,\n    class_mode='categorical',\n    batch_size=batch_size\n)\n\nvalidation_datagen = ImageDataGenerator(rescale=1./255)\nvalidation_generator = validation_datagen.flow_from_dataframe(\n    validate_df, \n    \"./train_data/\", \n    x_col='filename',\n    y_col='category',\n    target_size=IMAGE_SIZE,\n    class_mode='categorical',\n    batch_size=batch_size\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Fit the model","metadata":{}},{"cell_type":"code","source":"epochs=3 if FAST_RUN else 50\nhistory = model.fit(\n    train_generator,\n    epochs=epochs,\n    validation_data=validation_generator,\n    validation_steps=total_validate//batch_size,\n    steps_per_epoch=total_train//batch_size,\n    callbacks=callbacks,\n    shuffle = True, # 違う\n    verbose= 1\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Save weights","metadata":{}},{"cell_type":"code","source":"model.save_weights(\"xception_adam_model.h5\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Visualize Training","metadata":{}},{"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\nax1.plot(history.history['loss'], color='b', label=\"Training loss\")\nax1.plot(history.history['val_loss'], color='r', label=\"validation loss\")\nax1.set_xticks(np.arange(1, epochs, 1))\nax1.set_yticks(np.arange(0, 1, 0.1))\n\nax2.plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\nax2.plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nax2.set_xticks(np.arange(1, epochs, 1))\n\nlegend = plt.legend(loc='best', shadow=True)\nplt.tight_layout()\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Preparing Test Data","metadata":{}},{"cell_type":"code","source":"test_filenames = os.listdir(\"./test_data\")\ntest_labels = []\nfor test_filename in test_filenames:\n  test_label = test_filename.split('.')[0]\n  test_labels.append(test_label)\n\ntest_df = pd.DataFrame({\n    'filename' : test_filenames,\n    'label' : test_labels\n})\nnb_samples = test_df.shape[0]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Generate Test Data","metadata":{}},{"cell_type":"code","source":"test_gen = ImageDataGenerator(rescale=1./255)\ntest_generator = test_gen.flow_from_dataframe(\n    test_df,\n    \"./test_data/\",\n    x_col='filename',\n    y_col=None,\n    class_mode=None,\n    target_size=IMAGE_SIZE,\n    batch_size=batch_size, #batch_sizeが違う\n    shuffle=False\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Predict","metadata":{}},{"cell_type":"code","source":"predict = model.predict(test_generator, steps=np.ceil(nb_samples/batch_size))\n\ntest_df['category'] = np.argmax(predict, axis=-1)\ntest_df\n\nlabel_map = dict((v, k) for k, v in train_generator.class_indices.items())\ntest_df['category'] = test_df['category'].replace(label_map)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Visualize result","metadata":{}},{"cell_type":"code","source":"test_df['category'].value_counts().plot.bar()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Confusion matrix","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n  if normalize:\n    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n    print(\"Normalized confusion matrix\")\n  else:\n    print('Confusion matrix, without normalization')\n\n  print(cm)\n\n  plt.imshow(cm, interpolation='nearest', cmap=cmap)\n  plt.title(title)\n  plt.colorbar()\n  tick_marks = np.arange(len(classes))\n  plt.xticks(tick_marks, classes, rotation=90)\n  plt.yticks(tick_marks, classes)\n\n  fmt = '.2f' if normalize else 'd'\n  thresh = cm.max() / 2.\n  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n    plt.text(j, i, format(cm[i, j], fmt),\n             horizontalalignment=\"center\",\n             color=\"white\" if cm[i, j] > thresh else \"black\")\n\n  plt.tight_layout()\n  plt.ylabel('True label')\n  plt.xlabel('Predicted label')\n\nconfusion_mtx = confusion_matrix(test_df['label'], test_df['category'])\nplot_confusion_matrix(confusion_mtx, classes = range(7))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Caliculate F1 score(Accuracy)","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import f1_score\npoint = f1_score(test_df['label'], test_df['category'], average='micro')\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Convert to Percentage","metadata":{}},{"cell_type":"code","source":"print('accuracyは' + str(100 * point) + '%')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Submission","metadata":{}},{"cell_type":"code","source":"submission_df = test_df.copy()\nsubmission_df['id'] = submission_df['filename'].str.split('.').str[0]\nsubmission_df['label'] = submission_df['category']\nsubmission_df.drop(['filename', 'category'], axis=1, inplace=True)\nsubmission_df.to_csv('submission.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]}]}